# Communication Centralizer

An automated system that consolidates messages from multiple platforms (Email, LinkedIn, Handshake, Slack, Discord, etc.) into a single Google Sheet, then uses NLP to detect interview requests and auto-schedules them with Calendly and Google Calendar.

## Features

- Collects messages from:
  - Emails (Gmail/Outlook)
  - LinkedIn DMs (via PhantomBuster)
  - Handshake Messages (via web automation)
  - Slack and Discord
- Stores data in Google Sheets
- Identifies interview requests using spaCy (with LLM integration)
- Auto-schedules interviews with Calendly/Google Calendar

## Requirements

- **Docker** and **Docker Compose** (automatically installed by `setup.sh`)
- **Google Cloud Platform** account (for Sheets/Calendar)
- **PhantomBuster** account (for LinkedIn automation)
- **Calendly** account (for scheduling)
- **Slack** and **Discord** bot tokens (optional connectors)
- **AWS** account (if using the included CI/CD to deploy to an EC2 instance, but you can skip AWS if you just need local usage)

## Quick Setup (Single Best Way)

1. **Clone the repository**:
   ```bash
   git clone https://github.com/your-org/comm-centralizer.git
   cd comm-centralizer
   ```
2. **Run the setup script**:
   ```bash
   ./setup.sh
   ```
   This will:
   - Install Docker and Docker Compose (if missing)
   - Build Docker images
   - Create a Python virtual environment (via UV)
   - Prepare directories and configs
3. **Add credentials** to `config/credentials/` (see that folder's README for details).
4. **Set environment variables** in the `.env` file (you can copy `.env.example` as a starting point).
5. **Reload your shell or log out/log in** if prompted (Docker permissions).
6. **Start the app in development mode**:
   ```bash
   make docker-run-dev
   ```

## CI/CD Pipeline (GitHub Actions)

- Automatically tests, builds, and deploys the application when changes are pushed.
- By default:
  - **`develop`** branch â†’ deploys to staging (if configured).
  - **`main`** branch â†’ deploys to production (if configured).
- **Required GitHub Secrets** (if deploying to AWS):
  - `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_REGION`, `STAGING_EC2_IP`, `PRODUCTION_EC2_IP`, `EC2_SSH_PRIVATE_KEY`
- If you're not using AWS, you can ignore this part and just run locally or adapt it to your environment.

## Testing

Run tests locally or inside Docker:

```bash
# Run all tests (credentials + components)
make test

# Same tests inside Docker container
make docker-test
```

### Adding New Tests

- **Credential Tests**: place them in `tests/credentials/` and update `tests/run_credential_tests.py` if needed.
- **Component Tests**: place them in `tests/component/` following normal pytest naming conventions.

## Project Automation with Makefile

- `make help`: Lists all available commands.
- **Common commands**:
  - `make docker-run-dev` - Start the development environment
  - `make docker-stop` - Stop containers
  - `make docker-logs` - View logs
  - `make docker-build` - Rebuild containers after changes
  - `make uv-add package=xyz` - Add a Python dependency via UV
  - `make test` - Run all tests
  - `make ci-test` - Run all CI tests (linting, type checks, unit tests)

## VS Code Configuration (Optional)

1. Open Command Palette â†’ "Python: Select Interpreter"
2. Choose your Pyenv environment (`~/.pyenv/versions/...`)
3. Restart VS Code

This ensures imports (like `crontab`) are properly recognized.

## Simplified Workflow

1. **Install/Update** everything with `./setup.sh`.
2. **Develop** locally using `make docker-run-dev`.
3. **Push changes** to GitHub to trigger automated tests (and optionally deploy to AWS if you have that configured).
4. **Check logs** with `make docker-logs`.

## Project Structure

```bash
comm-centralizer/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ .dir_structure_cache.json   # Cache file for directory structure
â”‚   â”œâ”€â”€ deploy_to_ec2.sh            # Script for deploying to EC2
â”‚   â”œâ”€â”€ directory_printer.py        # Script for printing directory structure
â”‚   â”œâ”€â”€ ec2_security_setup.sh       # Script for setting up EC2 security
â”‚   â”œâ”€â”€ readme_update.log           # Log file for readme updates
â”‚   â”œâ”€â”€ schedule_job.py             # Script for scheduling jobs
â”‚   â”œâ”€â”€ setup_env_credentials.sh    # Script for setting up environment credentials
â”‚   â”œâ”€â”€ setup_monitoring.sh         # Script for setting up monitoring
â”‚   â””â”€â”€ update_readme_structure.py  # Script for updating readme structure
â”œâ”€â”€ .ruff_cache/
â”‚   â”œâ”€â”€ .gitignore                  # Git ignore file for cache
â”‚   â”œâ”€â”€ CACHEDIR.TAG                # Cache directory tag
â”‚   â””â”€â”€ content/
â”œâ”€â”€ terraform/
â”‚   â””â”€â”€ main.tf                     # Main Terraform configuration file
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.py                   # Configuration file
â”‚   â””â”€â”€ credentials/
â”‚       â”œâ”€â”€ .gitkeep                # Git keep file
â”‚       â”œâ”€â”€ README.md               # Credentials README
â”‚       â”œâ”€â”€ gmail_token.json        # Gmail token file
â”‚       â””â”€â”€ google_credentials.json  # Google credentials file
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                     # Main Python file
â”‚   â”œâ”€â”€ automation/
â”‚   â”‚   â””â”€â”€ puppeteer_scripts/
â”‚   â”‚       â”œâ”€â”€ handshake.js        # Puppeteer script for handshake
â”‚   â”‚       â”œâ”€â”€ index.ts            # TypeScript index file
â”‚   â”‚       â””â”€â”€ utils.js            # Utility script
â”‚   â”‚   â””â”€â”€ selenium_scripts/
â”‚   â”‚       â””â”€â”€ utils.py            # Selenium utility script
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ environment.py          # Environment configuration file
â”‚   â”œâ”€â”€ connectors/
â”‚   â”‚   â”œâ”€â”€ discord_connector.py    # Discord connector implementation
â”‚   â”‚   â”œâ”€â”€ email_connector.py      # Email connector implementation
â”‚   â”‚   â”œâ”€â”€ handshake_connector.py  # Handshake connector implementation
â”‚   â”‚   â”œâ”€â”€ linkedin_connector.py   # LinkedIn connector implementation
â”‚   â”‚   â””â”€â”€ slack_connector.py      # Slack connector implementation
â”‚   â”œâ”€â”€ processing/
â”‚   â”‚   â”œâ”€â”€ message_classifier.py   # Message classifier implementation
â”‚   â”‚   â””â”€â”€ nlp_processor.py        # NLP processor implementation
â”‚   â”œâ”€â”€ scheduling/
â”‚   â”‚   â”œâ”€â”€ calendly.py             # Calendly scheduling implementation
â”‚   â”‚   â””â”€â”€ google_calendar.py      # Google Calendar scheduling implementation
â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â””â”€â”€ google_sheets.py        # Google Sheets storage implementation
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ conftest.py                 # Configuration file for tests
â”‚   â”œâ”€â”€ component/
â”‚   â”‚   â”œâ”€â”€ README.md               # Component test README
â”‚   â”‚   â”œâ”€â”€ test_automation.py      # Automation test script
â”‚   â”‚   â”œâ”€â”€ test_connectors.py      # Connectors test script
â”‚   â”‚   â”œâ”€â”€ test_processing.py      # Processing test script
â”‚   â”‚   â”œâ”€â”€ test_scheduling.py      # Scheduling test script
â”‚   â”‚   â””â”€â”€ test_storage.py         # Storage test script
â”‚   â”œâ”€â”€ credentials/
â”‚   â”‚   â”œâ”€â”€ README.md               # Credentials test README
â”‚   â”‚   â”œâ”€â”€ test_calendly_credentials.py  # Calendly credentials test script
â”‚   â”‚   â”œâ”€â”€ test_discord_credentials.py   # Discord credentials test script
â”‚   â”‚   â”œâ”€â”€ test_email_credentials.py     # Email credentials test script
â”‚   â”‚   â”œâ”€â”€ test_openai_credentials.py    # OpenAI credentials test script
â”‚   â”‚   â”œâ”€â”€ test_phantombuster_credentials.py  # Phantombuster credentials test script
â”‚   â”‚   â”œâ”€â”€ test_sheets_credentials.py    # Google Sheets credentials test script
â”‚   â”‚   â””â”€â”€ test_slack_credentials.py     # Slack credentials test script
â”œâ”€â”€ .eslintrc.js                     # ESLint configuration file
â”œâ”€â”€ .pre-commit-config.yaml          # Pre-commit configuration file
â”œâ”€â”€ Dockerfile                       # Dockerfile for development
â”œâ”€â”€ Dockerfile.prod                  # Dockerfile for production
â”œâ”€â”€ Makefile                         # Makefile for project
â”œâ”€â”€ README.md                        # Project documentation
â”œâ”€â”€ TODOPROMPTS.txt                  # TODO prompts file
â”œâ”€â”€ comm_centralizer.log             # Project log file
â”œâ”€â”€ docker-compose.dev.yml           # Docker Compose file for development
â”œâ”€â”€ docker-compose.prod.yml          # Docker Compose file for production
â”œâ”€â”€ docker-compose.yml               # Docker Compose file
â”œâ”€â”€ package.json                     # Node.js package file
â”œâ”€â”€ pyproject.toml                   # Poetry project file
â”œâ”€â”€ pytest.ini                       # Pytest configuration file
â”œâ”€â”€ setup.sh                         # Setup script
â””â”€â”€ tsconfig.json                    # TypeScript configuration file
```

**That's it!** For most use cases, just run `setup.sh` and use `make docker-run-dev` to get going, then rely on the GitHub Actions pipeline to handle testing and production deployment.

## Architecture

```mermaid
graph TD
    subgraph "Input Sources"
        A1["ğŸ“§ Email"]
        A2["ğŸ’¼ LinkedIn"]
        A3["ğŸ¤ Handshake"]
        A4["ğŸ’¬ Slack/Discord"]
    end

    subgraph "Integration Layer"
        B["ğŸ”Œ Connectors"]
    end

    subgraph "Core Processing"
        C["âš™ï¸ Central Processing"]
        D["ğŸ§  NLP/Classification"]
    end

    subgraph "Output Systems"
        E["ğŸ“Š Google Sheets<br/>(Storage)"]
        F["ğŸ“… Calendly<br/>(Scheduling)"]
        G["ğŸ“† Google Calendar"]
    end

    A1 --> B
    A2 --> B
    A3 --> B
    A4 --> B

    B --> C
    C --> D

    D -->|Store Message Data| E
    D -->|Schedule Interview| F
    F --> G

    %% Styling
    classDef sources fill:#f9d5e5,stroke:#333,stroke-width:1px;
    classDef integration fill:#eeeeee,stroke:#333,stroke-width:1px;
    classDef processing fill:#d3e5ef,stroke:#333,stroke-width:1px;
    classDef outputs fill:#e5f5e0,stroke:#333,stroke-width:1px;

    class A1,A2,A3,A4 sources;
    class B integration;
    class C,D processing;
    class E,F,G outputs;
```

# Contributing

1. For the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Create a pull request

Please ensure you follow our coding standards (linting and type checking should pass).

# Adding New Connectors

To add a new connector, you can follow these steps:

1. Create a new file in the `src/connectors/` directory.
2. Implement the required interface methods (see existing connectors for examples)
3. Add credentials handling in `config/credentials/`
4. Update the main application to use your new connector
5. Add tests in `tests/component/` and `test/credentials`

# Troubleshooting

## Common Issues

- **Docker Permissions**: Ensure you've followed the setup instructions and reloaded your shell. Run `su - $USER` before running docker commands.
- **Authentication failures**: Double-check your credentials in `config/credentials/` and `.env`.
- **Scheduling not working**: Ensure your Calendly and Google Calendar are properly set up.

For more issues, check the logs with `make docker-logs`.
